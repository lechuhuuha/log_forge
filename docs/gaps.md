Kafka consumer commits before persistence: internal/queue/kafka_queue.go (lines 167-202) reads from Kafka with ReadMessage (auto-commits offsets on read) and immediately invokes the handler; if store.SaveBatch fails in the batch writer, the message is already acknowledged and lost, breaking reliability under failures.
Analytics output collides across days: internal/service/aggregation.go (line 126) writes summaries to analytics/summary_<hour>.json with no date component, so the 14:00 summary for today overwrites yesterday’s 14:00 and loses historical results. **Addressed:** analytics now mirrors the logs layout (`analytics/YYYY-MM-DD/summary_<HH>.json`).
Aggregator skips stored data outside the current hour: internal/service/aggregation.go (lines 59-69) only aggregates time.Now().UTC() every interval. Any log files from prior hours (e.g., after a restart or late-arriving data) are never summarized, so stored batches can remain unprocessed contrary to the “process stored data” requirement.
Observability gap: metrics only expose record counts/errors (logs_ingested_total, ingest_errors_total, aggregation_runs_total) in internal/metrics/metrics.go (lines 11-27); the challenge calls out “total number of received log batches,” which isn’t tracked. Invalid requests are co-mingled with backend errors under one counter. **Addressed:** added log_batches_received_total and invalid_requests_total counters and wired increments in ingestion and HTTP validation paths.
Tests don’t cover payload validation: only aggregation and ingestion-routing tests exist (internal/service/aggregation_test.go, internal/service/ingestion_test.go). There are no unit tests for /logs JSON/CSV parsing or validation failures, so the “core logic (validation, aggregation, etc.)” testing requirement is only partially met.
